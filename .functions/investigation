####################################
# Scraping
####################################

alias listserv='time get_listserv'

get_site_links() {
    local SITE=${1}
    wget -w 1 --no-check-certificate --spider -r ${SITE} 2>&1 | grep '^--' | awk '{ print $3 }' | grep -v '\.\(css\|js\|png\|gif\|jpg\|JPG\)$' > urls.txt
}


# One of @janmoesen’s ProTip™s
for method in GET HEAD POST PUT DELETE TRACE OPTIONS; do
        alias "${method}"="lwp-request -m '${method}'"
done


get_all_site_links() {
    local URL="$1"
    local tmpdir=$(mktemp -dt "$(basename "$0").XXXXX")
    wget -m "${URL}" \
         --directory-prefix="${tmpdir}" \
         2>&1 \
        | grep '^--' \
        | awk '{ print $3 }' \
        | grep -v '\.\(css\|js\|png\|gif\|jpg\|JPG\)$'
    rm -fr "${tmpdir}"
}


get_site_archives() {
    year=$(date +"%Y")
    curl "http://timetravel.mementoweb.org/api/json/${year}/${1}" | jq
}

####################################
# Encode / Decode
####################################

# URL-encode strings

alias encode_url_percent='python -c "import sys, urllib as ul; print ul.quote_plus(sys.argv[1]);"'

# Url-decode strings
alias decode_percent='sed "s@+@ @g;s@%@\\\\x@g" | xargs -0 printf "%b"'


# UTF-8-encode a string of Unicode symbols
encode_x() {
        local args
        mapfile -t args < <(printf "%s" "$*" | xxd -p -c1 -u)
        printf "\\\\x%s" "${args[@]}"
        # print a newline unless we’re piping the output to another program
        if [ -t 1 ]; then
                echo ""; # newline
        fi
}

# Decode \x{ABCD}-style Unicode escape sequences
decode_x() {
        perl -e "binmode(STDOUT, ':utf8'); print \"$*\""
        # print a newline unless we’re piping the output to another program
        if [ -t 1 ]; then
                echo ""; # newline
        fi
}


####################################
# OSINT
####################################

# Run `dig` and display the most useful info
function digga() {
        dig +nocmd "$1" any +multiline +noall +answer;
}

# Show all the names (CNs and SANs) listed in the SSL certificate
# for a given domain
function getcertnames() {
        if [ -z "${1}" ]; then
                echo "ERROR: No domain specified.";
                return 1;
        fi;

        local domain="${1}";
        echo "Testing ${domain}…";
        echo ""; # newline

        local tmp=$(echo -e "GET / HTTP/1.0\nEOT" \
                | openssl s_client -connect "${domain}:443" -servername "${domain}" 2>&1);

        if [[ "${tmp}" = *"-----BEGIN CERTIFICATE-----"* ]]; then
                local certText=$(echo "${tmp}" \
                        | openssl x509 -text -certopt "no_aux, no_header, no_issuer, no_pubkey, \
                        no_serial, no_sigdump, no_signame, no_validity, no_version");
                echo "Common Name:";
                echo ""; # newline
                echo "${certText}" | grep "Subject:" | sed -e "s/^.*CN=//" | sed -e "s/\/emailAddress=.*//";
                echo ""; # newline
                echo "Subject Alternative Name(s):";
                echo ""; # newline
                echo "${certText}" | grep -A 1 "Subject Alternative Name:" \
                        | sed -e "2s/DNS://g" -e "s/ //g" | tr "," "\n" | tail -n +2;
                return 0;
        else
                echo "ERROR: Certificate not found.";
                return 1;
        fi;
}

############################################
## Indicator Capture
############################################




# `-u` for unique
# -t \: for colon delimited
# -k1,1 for key field 1
# alias unique_http_or_https_transport="grep 'http' | sort -u -t\/ -k4,4"


http_unique() {
    grep -Eo "http[s]://[ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789\._~:/\?#\&\(\)\*+\,\;=@ -]+" "${1}" \
        | sort -u -t\/ -k4,4
        # `-u` for unique
        # -t \: for colon delimited
        # -k1,1 for key field 1
}


search_dir_for_urls() {
    grep -r --only-matching --perl-regexp "http(s?):\/\/[^ \"\(\)\<\>]*" "${1}"
}



############################################
## Email
############################################

msg2eml() {
    # Convert a .msg email to a .eml email
    # sudo apt-get install libemail-outlook-message-perl libemail-localdelivery-perl
    local MSG_FILE="${1}"
    local EML_FILE="${2}"
    ~/tools/msg2eml/msgconvert.pl --verbose --mbox "${EML_FILE}" "${MSG_FILE}"
}

read_email() {
    # Take a .eml email and open it up in mutt
    # sudo apt-get install mutt procmail
    local curdir=$(pwd)
    local tmpdir
    tmpdir=$(mktemp -dt "$(basename "$0").XXXXX")
    local eml_name
    eml_name=$(basename "$0")
    cp -f "$1" "${tmpdir}/${eml_name}"
    cd "${tmpdir}"
    formail -b < "${eml_name}" > "${eml_name}.mbox"
    neomutt -F '' -f "${eml_name}.mbox"
    cd "${curdir}"
    echo "Files Can be found in ${tmpdir}"
}


# ===== VIPER ALIASES =====
# For use in viper docker container.

alias oledump="python2 /tools/oledump/oledump.py --plugindir /tools/oledump"

#  --pluginoptions=-k
alias msgdump="python2 /tools/oledump/oledump.py --plugindir /tools/oledump -q -p plugin_msg"




############################################
## Android
############################################

apk_certificate() {
    keytool -list -printcert -jarfile "${1}"
}

apk_verify_signature() {
    jarsigner -verify -verbose:summary -certs "${1}"
}


############################################
## Viper Helpers
############################################

get_shortened_from_viper_line() {
    # For reading shortened links copied from a pdf using viper `strings -N`
    local viper_line="$1"
    local url=$(echo  "${viper_line}" | sed 's/^ - .*\/URI (\(.*\)).*$/\1/')
    local location=$(curl -sI "${url}" | grep Location | cut -d : -f 2-)
    printf "%s,%s\n" "${url}" "${location}"
}

read_viper_url_file() {
    # $1 == url file
    # $2 == output file to write links to
    if [ $# -eq 2 ]; then
        echo "OVERWRITING FILE: $2"
        printf "Continue? "
        read
        echo "shortened_link,destination_url" > "$2"
    fi
    local filelen=$(wc -l "$1")
    iterator=0
    while IFS='' read -r viper_line || [[ -n "$viper_line" ]]; do
        local printable=$(get_shortened_from_viper_line "${viper_line}")
        if [ $# -eq 2 ]; then
            iterator=$(("$iterator" + 1))
            printf "Getting %s of ${filelen}\r" "$iterator"
            printf "%s\n" "${printable}" >> "$2"
        else
            printf "%s\n" "${printable}"
        fi
    done < "$1"
    printf "\n"
}

get_thug_from_viper_url_file() {
    # $1 == file from read_viper_url_file
    # $2 == output file to write location of thug data
    if [ $# -eq 2 ]; then
        echo "OVERWRITING FILE: $2"
        printf "Continue? "
        read
        echo "shortened_link,thug_data" > "$2"
    else
        printf "Please provide an output file \n"
        return 1
    fi
    # set -x
    local filelen=$(wc -l "$1" | cut -d ' ' -f1 )
    filelen=$(("$filelen" - 1))
    iterator=0
    # local url_list=$(sed 1,1d "$1")
    local url_list=$(sed 1,1d "$1" | cut -d , -f2 | sed '/^\s*$/d' | sort | uniq)
    # echo "$url_list"
    while IFS='' read -r url_line || [[ -n "$url_line" ]]; do
        iterator=$(("$iterator" + 1))
        #printf "%s,%s\n"
        local trimmed_url=$(echo "${url_line}" | tr -d '[:space:]')
        printf "Getting %s:\n %s of %s\n" "${trimmed_url}" "$iterator" "${filelen}"
        local output_path=$(thug_unassisted "${trimmed_url}" | grep "Thug Output Path" | sed 's/.*\(Thug Output Path: \)\(\/.*\).*$/\2/')
        printf "%s,%s\n" "${trimmed_url}" "${output_path}" >> "$2"
        #printf "%s,%s\n" "${url_line}" "${output_path}"
        # local printable=$(get_shortened_from_viper_line "${viper_line}")
    done <<< "$url_list"
    # set +x
}

get_bitly_hashes() {
    # ONLY gets bit.ly hashes (for harpoon)
    # $1 == file from read_viper_url_file
    # $2 == output file to write location of thug daat
    cat "$1" | cut -d, -f 1| grep "bit\.ly" | sed 's/http[s]*:\/\/bit\.ly\/\(.*\)/\1/' > "$2"
}



############################################
## Extraction From Files
############################################

extract_images() {
    local filename="$1"
    exiftool -a -b -ee -embeddedimage -W Image_%.3g3.%s "${filename}"
    # exiftool -a -b -ee -W Embeded_%.3g3.%s "${filename}"
    # Extract embedded JPG and JP2 images from a PDF file.  The output images will have file names like
    # "Image_#.jpg" or "Image_#.jp2", where "#" is the ExifTool family 3 embedded document number for the
    # image.
    # Use -g3 or -G3 to identify the originating document for extracted information.
    
}

alias exiftool_extract_images=extract_images

extract_ALL_metadata() {
    local filename="$1"
    exiftool -a -ee -u -g1 -api RequestAll=3 "${filename}"
# Print all meta information in an image, including duplicate and unknown tags, sorted by group (for family 1). For performance reasons, this command may not extract all available metadata. (Metadata in embedded documents, metadata extracted by external utilities, and metadata requiring excessive processing time may not be extracted). Add -ee and -api RequestAll=3 to the command to extract absolutely everything available.

}

alias exiftool_show_ALL=extract_ALL_metadata